{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/libs/buildlib\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: build>=1.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (1.0.3)\n",
      "Requirement already satisfied: torch>=2.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (2.1.2)\n",
      "Requirement already satisfied: transformers in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (4.36.2)\n",
      "Requirement already satisfied: pytest in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (7.4.3)\n",
      "Requirement already satisfied: aiohttp in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already satisfied: packaging>=19.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from build>=1.0) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from build>=1.0) (1.0.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from build>=1.0) (7.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from build>=1.0) (2.0.1)\n",
      "Requirement already satisfied: filelock in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (4.9.0)\n",
      "Requirement already satisfied: sympy in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from torch>=2.0) (2023.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (1.24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: iniconfig in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pytest) (2.0.0)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pytest) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pytest) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from aiohttp) (4.0.3)\n",
      "Requirement already satisfied: python-on-whales>=0.64 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from buildlib==1.0.0) (0.68.0)\n",
      "Requirement already satisfied: snowflake-connector-python>=3.2.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (3.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from importlib-metadata>=4.6->build>=1.0) (3.17.0)\n",
      "Requirement already satisfied: pydantic!=2.0.*,<3,>=1.9 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from python-on-whales>=0.64->buildlib==1.0.0) (2.5.2)\n",
      "Requirement already satisfied: typer>=0.4.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from python-on-whales>=0.64->buildlib==1.0.0) (0.9.0)\n",
      "Requirement already satisfied: asn1crypto<2.0.0,>0.24.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (1.5.1)\n",
      "Requirement already satisfied: cffi<2.0.0,>=1.9 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (1.16.0)\n",
      "Requirement already satisfied: cryptography<42.0.0,>=3.1.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (41.0.7)\n",
      "Requirement already satisfied: pyOpenSSL<24.0.0,>=16.2.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (23.3.0)\n",
      "Requirement already satisfied: pyjwt<3.0.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2.8.0)\n",
      "Requirement already satisfied: pytz in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2023.3.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (3.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2023.11.17)\n",
      "Requirement already satisfied: sortedcontainers>=2.4.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2.4.0)\n",
      "Requirement already satisfied: platformdirs<4.0.0,>=2.6.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (3.11.0)\n",
      "Requirement already satisfied: tomlkit in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (0.12.3)\n",
      "Requirement already satisfied: urllib3<2.0.0,>=1.21.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (1.26.18)\n",
      "Requirement already satisfied: pandas<2.2.0,>=1.0.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2.0.3)\n",
      "Requirement already satisfied: pyarrow in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (14.0.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from jinja2->torch>=2.0) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from sympy->torch>=2.0) (1.3.0)\n",
      "Requirement already satisfied: pycparser in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from cffi<2.0.0,>=1.9->snowflake-connector-python>=3.2.1->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2.21)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pydantic!=2.0.*,<3,>=1.9->python-on-whales>=0.64->buildlib==1.0.0) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.14.5 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from pydantic!=2.0.*,<3,>=1.9->python-on-whales>=0.64->buildlib==1.0.0) (2.14.5)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from typer>=0.4.1->python-on-whales>=0.64->buildlib==1.0.0) (8.1.7)\n",
      "Requirement already satisfied: six>=1.5 in /Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages (from python-dateutil>=2.8.2->pandas<2.2.0,>=1.0.0->snowflake-connector-python[pandas]>=3.2.1->buildlib==1.0.0) (1.16.0)\n",
      "Building wheels for collected packages: buildlib\n",
      "  Building editable for buildlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for buildlib: filename=buildlib-1.0.0-0.editable-py3-none-any.whl size=1457 sha256=bb5f929badaf3a24a415310e4e3fd7ec4afd3cc133dccd77d15ff3abdfc6ca71\n",
      "  Stored in directory: /private/var/folders/_t/r3r35b_50cl44c_njstr2ykw0000gn/T/pip-ephem-wheel-cache-umvhwiqk/wheels/98/aa/29/91c30cc69abfc62073290dcfac26d918a56b77f98bcd5394c7\n",
      "Successfully built buildlib\n",
      "Installing collected packages: buildlib\n",
      "  Attempting uninstall: buildlib\n",
      "    Found existing installation: buildlib 1.0.0\n",
      "    Uninstalling buildlib-1.0.0:\n",
      "      Successfully uninstalled buildlib-1.0.0\n",
      "Successfully installed buildlib-1.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Requirements.\n",
    "%pip install \"build>=1.0\" \"torch>=2.0\" \"transformers\" -e \"../../libs/buildlib\" \"pytest\" \"aiohttp\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmerrick/miniconda3/envs/spcs-embedding/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import buildlib\n",
    "import pytest\n",
    "from build import ProjectBuilder\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In order to create a custom text embedding service, we need to create a Docker image, push it to Snowflake, and tell Snowflake to deploy it. In addition to building, pushing, and deploying, this notebook will also cover how to test your Docker image locally to speed up the develoment cycle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building\n",
    "\n",
    "In order to build an image for our custom service, we put custom data (a `data/` directory) and logic (an `embed.py`, plus a `requirements.txt` specifying any dependencies) into the `build/` directory, and then we use the `buildlib` to run the build process (`buildlib.build()`).\n",
    "\n",
    "## What is `buildlib`?\n",
    "\n",
    "`Buildlib` is a small Python package that hard-codes much of the boilerplate needed to deploy a text embedding service for you. On the Docker side, it uses the [python-on-whales](https://github.com/gabrieldemarmiesse/python-on-whales) package to provide easy-to-use Python functions that trigger Docker builds specifically for the text embedding service. On the Snowflake side, it uses plain f-string templating and the Snowflake Python connector to generate and run the SQL commands that set up your service in Snowflake. If you're ever curious about what a particular `buildlib` function is doing behind the scenes, don't be afraid to check out the source code -- it's not that complicated!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clear out `build/`\n",
    "\n",
    "Let's start with a clean slate by deleting and recreating an empty `build/`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUILD_DIR = Path(\".\").resolve().parents[1] / \"build\"\n",
    "shutil.rmtree(BUILD_DIR, ignore_errors=True)\n",
    "BUILD_DIR.mkdir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the data\n",
    "\n",
    "For this example, we will use the [`e5-base-v2`](https://huggingface.co/intfloat/e5-base-v2) model from Microsoft. We'll demonstrate how to preload the model weights directly into our Docker image for simpler deployment.\n",
    "\n",
    "Rather than just using the [`transformers`](https://pypi.org/project/transformers/) library directly, we'll also demonstrate how to include a custom library into the Docker image by building a [pure Python wheel](https://packaging.python.org/en/latest/guides/distributing-packages-using-setuptools/#pure-python-wheels) and including that in the `data/` alongside the model weights. The library we demonstrate on is `embed_lib/`, a small example library we wrote to call the E5 model via `transformers`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put model weights into `build/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading intfloat/e5-base-v2 and saving tokenizer and weights to /Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data\n"
     ]
    }
   ],
   "source": [
    "# Downloading the model weights.\n",
    "MODEL_NAME = \"intfloat/e5-base-v2\"\n",
    "MODEL_EMBEDDING_DIM = 768\n",
    "DATA_DIR = BUILD_DIR / \"data\"\n",
    "TOKENISER_DIR = DATA_DIR / \"tokenizer\"\n",
    "MODEL_DIR = DATA_DIR / \"model\"\n",
    "\n",
    "print(f\"Downloading {MODEL_NAME} and saving tokenizer and weights to {DATA_DIR}\")\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained(MODEL_NAME)\n",
    "model = BertModel.from_pretrained(MODEL_NAME)\n",
    "assert isinstance(model, BertModel)  # This is for typechecking.\n",
    "tokenizer.save_pretrained(TOKENISER_DIR)\n",
    "model.save_pretrained(MODEL_DIR)\n",
    "\n",
    "# Validate that our saved files work by loading from them.\n",
    "tokenizer = BertTokenizerFast.from_pretrained(TOKENISER_DIR)\n",
    "model = BertModel.from_pretrained(MODEL_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put packaged code into `build/data/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "running egg_info\n",
      "writing src/embed_lib.egg-info/PKG-INFO\n",
      "writing dependency_links to src/embed_lib.egg-info/dependency_links.txt\n",
      "writing requirements to src/embed_lib.egg-info/requires.txt\n",
      "writing top-level names to src/embed_lib.egg-info/top_level.txt\n",
      "reading manifest file 'src/embed_lib.egg-info/SOURCES.txt'\n",
      "writing manifest file 'src/embed_lib.egg-info/SOURCES.txt'\n",
      "installing to build/bdist.macosx-11.1-arm64/wheel\n",
      "running install\n",
      "running install_lib\n",
      "creating build/bdist.macosx-11.1-arm64/wheel\n",
      "creating build/bdist.macosx-11.1-arm64/wheel/embed_lib\n",
      "copying build/lib/embed_lib/e5.py -> build/bdist.macosx-11.1-arm64/wheel/embed_lib\n",
      "copying build/lib/embed_lib/__init__.py -> build/bdist.macosx-11.1-arm64/wheel/embed_lib\n",
      "copying build/lib/embed_lib/_batch_iter_util.py -> build/bdist.macosx-11.1-arm64/wheel/embed_lib\n",
      "running install_egg_info\n",
      "Copying src/embed_lib.egg-info to build/bdist.macosx-11.1-arm64/wheel/embed_lib-1.0.0-py3.8.egg-info\n",
      "running install_scripts\n",
      "creating build/bdist.macosx-11.1-arm64/wheel/embed_lib-1.0.0.dist-info/WHEEL\n",
      "creating '/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data/.tmp-ssok5q74/embed_lib-1.0.0-py3-none-any.whl' and adding 'build/bdist.macosx-11.1-arm64/wheel' to it\n",
      "adding 'embed_lib/__init__.py'\n",
      "adding 'embed_lib/_batch_iter_util.py'\n",
      "adding 'embed_lib/e5.py'\n",
      "adding 'embed_lib-1.0.0.dist-info/METADATA'\n",
      "adding 'embed_lib-1.0.0.dist-info/WHEEL'\n",
      "adding 'embed_lib-1.0.0.dist-info/top_level.txt'\n",
      "adding 'embed_lib-1.0.0.dist-info/RECORD'\n",
      "removing build/bdist.macosx-11.1-arm64/wheel\n",
      "Built /Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data/embed_lib-1.0.0-py3-none-any.whl\n"
     ]
    }
   ],
   "source": [
    "# Package our Python package into a wheel in the `data/` directory.\n",
    "wheel_filename = ProjectBuilder(Path(\".\") / \"embed_lib\").build(\n",
    "    distribution=\"wheel\", output_directory=DATA_DIR\n",
    ")\n",
    "print(f\"Built {wheel_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the logic\n",
    "\n",
    "In order to actually use our custom package, load our model weights, and perform text embedding, we need to implement the core logic of text embedding. This is done by implementing `get_embed_fn()` inside a file called `embed.py`. The function `get_embed_fn` should load model weights and return a function that maps a single input consisting of a `Sequence[str]` into a single 2d `numpy` array of datatype `np.float32`. Below we give an example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implement `get_embed_fn` inside `build/embed.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../../build/embed.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../build/embed.py\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from typing import Callable\n",
    "from typing import cast\n",
    "from typing import Sequence\n",
    "\n",
    "import embed_lib.e5\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers.models.bert.modeling_bert import BertModel\n",
    "from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast\n",
    "\n",
    "MAX_BATCH_SIZE = 4\n",
    "\n",
    "\n",
    "def get_embed_fn() -> Callable[[Sequence[str]], np.ndarray]:\n",
    "    # Load the model into memory.\n",
    "    logger = logging.getLogger(__name__)\n",
    "    data_dir = Path(os.environ[\"BUILD_ROOT\"]) / \"data\"\n",
    "    logger.info(\"[get_embed_fn]Loading model from disk to memory\")\n",
    "    e5_model = embed_lib.e5.load_e5_model(\n",
    "        tokenizer_path=data_dir / \"tokenizer\", model_path=data_dir / \"model\"\n",
    "    )\n",
    "    logger.info(f\"[get_embed_fn]CUDA available: {torch.cuda.is_available()}\")\n",
    "\n",
    "    def embed(texts: Sequence[str]) -> np.ndarray:\n",
    "        result_tensor = embed_lib.e5.embed(\n",
    "            e5_model=e5_model,\n",
    "            texts=texts,\n",
    "            batch_size=MAX_BATCH_SIZE,\n",
    "            normalize=True,\n",
    "            progress_bar=False,\n",
    "        )\n",
    "        result_array = result_tensor.cpu().numpy().astype(np.float32)\n",
    "        return result_array\n",
    "\n",
    "    return embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add a `build/requirements.txt`\n",
    "\n",
    "We also need to specify the requirements for our embedding logic. During the build, we will populate the `BUILD_ROOT` environment variable, which enables you to include custom packages (like your `embed_lib` wheel) in your `requirements.txt` by absolute filepath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ../../build/requirements.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../../build/requirements.txt\n",
    "\n",
    "${BUILD_ROOT}/data/embed_lib-1.0.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure\n",
    "\n",
    "NOTE: We use f-string templating here to inject the value of the `MODEL_EMBEDDING_DIM` constant into the file. You can also use the same `%%writefile` magic as above, but in that case you must include the literal value (i.e. `768`) not the name of the constant, since in the file you're writing this constant is not defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(BUILD_DIR / \"config.py\").write_text(\n",
    "f\"\"\"from service_config import Configuration\n",
    "\n",
    "USER_CONFIG = Configuration(embedding_dim={MODEL_EMBEDDING_DIM})\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build!\n",
    "\n",
    "Now that all the pieces are in place inside `build/`, we can trigger a build via `buildlib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/config.py'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/embed.py'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/requirements.txt'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data/tokenizer'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data/model'),\n",
       " PosixPath('/Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service/build/data/embed_lib-1.0.0-py3-none-any.whl')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now have all the pieces we need to build our service!\n",
    "list(BUILD_DIR.iterdir()) + list(DATA_DIR.iterdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 [internal] load build definition from Dockerfile\n",
      "#1 transferring dockerfile: 2.48kB done\n",
      "#1 DONE 0.0s\n",
      "\n",
      "#2 [internal] load .dockerignore\n",
      "#2 transferring context: 2B done\n",
      "#2 DONE 0.0s\n",
      "\n",
      "#3 [internal] load metadata for docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04\n",
      "#3 DONE 1.5s\n",
      "\n",
      "#4 [ 1/14] FROM docker.io/nvidia/cuda:12.1.0-cudnn8-runtime-ubuntu22.04@sha256:f3a7fb39fa3ffbe54da713dd2e93063885e5be2f4586a705c39031b8284d379a\n",
      "#4 DONE 0.0s\n",
      "\n",
      "#5 [internal] load build context\n",
      "#5 transferring context: 439.02MB 2.6s done\n",
      "#5 DONE 2.6s\n",
      "\n",
      "#6 [ 9/14] COPY ./services_common_code ./services_common_code\n",
      "#6 CACHED\n",
      "\n",
      "#7 [ 5/14] RUN chmod +x ~/miniconda.sh &&     bash ~/miniconda.sh -b -p /opt/conda &&     rm ~/miniconda.sh &&     /opt/conda/bin/conda install -y python=3.8 &&     /opt/conda/bin/conda clean -ya\n",
      "#7 CACHED\n",
      "\n",
      "#8 [ 6/14] COPY ./libs ./libs\n",
      "#8 CACHED\n",
      "\n",
      "#9 [ 7/14] COPY ./service_api ./service_api\n",
      "#9 CACHED\n",
      "\n",
      "#10 [ 8/14] COPY ./service_embed_loop ./service_embed_loop\n",
      "#10 CACHED\n",
      "\n",
      "#11 [ 4/14] RUN case linux/amd64 in          \"linux/arm64\")  MINICONDA_ARCH=aarch64  ;;          *)              MINICONDA_ARCH=x86_64   ;;     esac &&     curl -fsSL -v -o ~/miniconda.sh -O  \"https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-${MINICONDA_ARCH}.sh\"\n",
      "#11 CACHED\n",
      "\n",
      "#12 [ 2/14] WORKDIR /root\n",
      "#12 CACHED\n",
      "\n",
      "#13 [ 3/14] RUN apt-get update && DEBIAN_FRONTEND=noninteractive apt-get install -y --no-install-recommends         curl &&     rm -rf /var/lib/apt/lists/*\n",
      "#13 CACHED\n",
      "\n",
      "#14 [10/14] RUN python -m venv --copies --prompt api create venv_api     && python -m venv --copies --prompt embed_loop create venv_embed_loop     && ./venv_api/bin/python -m pip install -r ./services_common_code/requirements.txt     && ./venv_api/bin/python -m pip install -r ./service_api/requirements.txt     && ./venv_embed_loop/bin/python -m pip install -r ./services_common_code/requirements.txt     && ./venv_embed_loop/bin/python -m pip install -r ./service_embed_loop/requirements.txt\n",
      "#14 CACHED\n",
      "\n",
      "#15 [11/14] COPY ./build ./build\n",
      "#15 DONE 0.6s\n",
      "\n",
      "#16 [12/14] RUN     mv ./build/data ./data     && mv ./build/config.py ./services_common_code/config.py     && mv ./build/embed.py ./service_embed_loop/embed.py\n",
      "#16 DONE 0.7s\n",
      "\n",
      "#17 [13/14] RUN ./venv_embed_loop/bin/python -m pip install -r ./build/requirements.txt\n",
      "#17 1.782 Processing ./data/embed_lib-1.0.0-py3-none-any.whl\n",
      "#17 2.759 Collecting torch==2.0.1\n",
      "#17 3.142   Downloading torch-2.0.1-cp38-cp38-manylinux1_x86_64.whl (619.9 MB)\n",
      "#17 83.92      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 619.9/619.9 MB 2.2 MB/s eta 0:00:00\n",
      "#17 116.3 Collecting tqdm==4.65.0\n",
      "#17 116.4   Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
      "#17 116.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.1/77.1 kB 7.2 MB/s eta 0:00:00\n",
      "#17 116.4 Requirement already satisfied: numpy==1.24.2 in ./venv_embed_loop/lib/python3.8/site-packages (from embed-lib==1.0.0->-r ./build/requirements.txt (line 2)) (1.24.2)\n",
      "#17 116.8 Collecting transformers==4.30.1\n",
      "#17 116.9   Downloading transformers-4.30.1-py3-none-any.whl (7.2 MB)\n",
      "#17 117.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.2/7.2 MB 7.2 MB/s eta 0:00:00\n",
      "#17 118.6 Collecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
      "#17 118.6   Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "#17 120.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 21.0/21.0 MB 12.2 MB/s eta 0:00:00\n",
      "#17 121.6 Collecting networkx\n",
      "#17 121.7   Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
      "#17 121.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 12.5 MB/s eta 0:00:00\n",
      "#17 122.2 Collecting sympy\n",
      "#17 122.2   Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "#17 122.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 12.8 MB/s eta 0:00:00\n",
      "#17 123.1 Collecting nvidia-curand-cu11==10.2.10.91\n",
      "#17 123.2   Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "#17 127.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 54.6/54.6 MB 11.2 MB/s eta 0:00:00\n",
      "#17 130.8 Collecting typing-extensions\n",
      "#17 130.9   Using cached typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "#17 130.9 Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
      "#17 131.0   Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "#17 131.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 11.8/11.8 MB 12.9 MB/s eta 0:00:00\n",
      "#17 132.6 Collecting nvidia-cusparse-cu11==11.7.4.91\n",
      "#17 132.7   Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "#17 147.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 173.2/173.2 MB 8.1 MB/s eta 0:00:00\n",
      "#17 156.7 Collecting nvidia-nccl-cu11==2.14.3\n",
      "#17 156.7   Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "#17 171.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.1/177.1 MB 6.5 MB/s eta 0:00:00\n",
      "#17 180.6 Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
      "#17 180.6   Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "#17 180.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 849.3/849.3 kB 11.8 MB/s eta 0:00:00\n",
      "#17 180.8 Collecting nvidia-nvtx-cu11==11.7.91\n",
      "#17 180.9   Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "#17 180.9      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 98.6/98.6 kB 9.8 MB/s eta 0:00:00\n",
      "#17 181.0 Collecting nvidia-cufft-cu11==10.9.0.58\n",
      "#17 181.1   Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "#17 209.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 168.4/168.4 MB 4.1 MB/s eta 0:00:00\n",
      "#17 218.0 Collecting triton==2.0.0\n",
      "#17 218.1   Downloading triton-2.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.2 MB)\n",
      "#17 230.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.2/63.2 MB 4.1 MB/s eta 0:00:00\n",
      "#17 233.4 Collecting nvidia-cublas-cu11==11.10.3.66\n",
      "#17 233.5   Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "#17 295.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 317.1/317.1 MB 2.8 MB/s eta 0:00:00\n",
      "#17 311.7 Collecting filelock\n",
      "#17 311.7   Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "#17 311.9 Collecting nvidia-cudnn-cu11==8.5.0.96\n",
      "#17 312.0   Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "#17 453.4      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 557.1/557.1 MB 2.3 MB/s eta 0:00:00\n",
      "#17 481.9 Collecting jinja2\n",
      "#17 481.9   Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
      "#17 482.0      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 1.8 MB/s eta 0:00:00\n",
      "#17 482.1 Collecting nvidia-cusolver-cu11==11.4.0.1\n",
      "#17 482.2   Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "#17 506.8      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 102.6/102.6 MB 4.6 MB/s eta 0:00:00\n",
      "#17 514.8 Collecting pyyaml>=5.1\n",
      "#17 514.9   Downloading PyYAML-6.0.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (736 kB)\n",
      "#17 515.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 736.6/736.6 kB 3.9 MB/s eta 0:00:00\n",
      "#17 517.5 Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
      "#17 517.5   Downloading tokenizers-0.13.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "#17 519.2      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.8/7.8 MB 4.5 MB/s eta 0:00:00\n",
      "#17 520.0 Collecting huggingface-hub<1.0,>=0.14.1\n",
      "#17 520.0   Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
      "#17 520.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 311.7/311.7 kB 3.3 MB/s eta 0:00:00\n",
      "#17 521.4 Collecting safetensors>=0.3.1\n",
      "#17 521.5   Downloading safetensors-0.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "#17 521.7      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 6.0 MB/s eta 0:00:00\n",
      "#17 522.0 Collecting packaging>=20.0\n",
      "#17 522.1   Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "#17 522.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.0/53.0 kB 6.3 MB/s eta 0:00:00\n",
      "#17 522.4 Collecting requests\n",
      "#17 522.5   Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "#17 522.5      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 62.6/62.6 kB 7.3 MB/s eta 0:00:00\n",
      "#17 527.3 Collecting regex!=2019.12.17\n",
      "#17 527.4   Downloading regex-2023.10.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (776 kB)\n",
      "#17 527.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 777.0/777.0 kB 4.2 MB/s eta 0:00:00\n",
      "#17 527.9 Collecting wheel\n",
      "#17 528.0   Using cached wheel-0.42.0-py3-none-any.whl (65 kB)\n",
      "#17 528.0 Requirement already satisfied: setuptools in ./venv_embed_loop/lib/python3.8/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1->embed-lib==1.0.0->-r ./build/requirements.txt (line 2)) (56.0.0)\n",
      "#17 528.3 Collecting lit\n",
      "#17 528.3   Downloading lit-17.0.6.tar.gz (153 kB)\n",
      "#17 528.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 153.0/153.0 kB 6.1 MB/s eta 0:00:00\n",
      "#17 529.0   Installing build dependencies: started\n",
      "#17 535.0   Installing build dependencies: finished with status 'done'\n",
      "#17 535.0   Getting requirements to build wheel: started\n",
      "#17 535.9   Getting requirements to build wheel: finished with status 'done'\n",
      "#17 536.0   Installing backend dependencies: started\n",
      "#17 538.8   Installing backend dependencies: finished with status 'done'\n",
      "#17 538.8   Preparing metadata (pyproject.toml): started\n",
      "#17 539.8   Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "#17 541.3 Collecting cmake\n",
      "#17 541.4   Downloading cmake-3.28.1-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (26.3 MB)\n",
      "#17 547.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 26.3/26.3 MB 4.7 MB/s eta 0:00:00\n",
      "#17 549.5 Collecting fsspec>=2023.5.0\n",
      "#17 549.5   Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "#17 549.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 169.0/169.0 kB 3.2 MB/s eta 0:00:00\n",
      "#17 550.6 Collecting MarkupSafe>=2.0\n",
      "#17 550.7   Downloading MarkupSafe-2.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "#17 551.0 Collecting idna<4,>=2.5\n",
      "#17 551.0   Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "#17 552.0 Collecting charset-normalizer<4,>=2\n",
      "#17 552.1   Downloading charset_normalizer-3.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "#17 552.1      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.1/141.1 kB 3.8 MB/s eta 0:00:00\n",
      "#17 552.5 Collecting urllib3<3,>=1.21.1\n",
      "#17 552.6   Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
      "#17 552.6      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 104.6/104.6 kB 5.8 MB/s eta 0:00:00\n",
      "#17 552.8 Collecting certifi>=2017.4.17\n",
      "#17 552.9   Using cached certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
      "#17 553.0 Collecting mpmath>=0.19\n",
      "#17 553.1   Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "#17 553.3      ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 3.8 MB/s eta 0:00:00\n",
      "#17 553.9 Building wheels for collected packages: lit\n",
      "#17 553.9   Building wheel for lit (pyproject.toml): started\n",
      "#17 555.1   Building wheel for lit (pyproject.toml): finished with status 'done'\n",
      "#17 555.1   Created wheel for lit: filename=lit-17.0.6-py3-none-any.whl size=93255 sha256=92d39d42d62e7b6759941624f3820aeaf02482784273439923e6d8f544bb79c1\n",
      "#17 555.1   Stored in directory: /root/.cache/pip/wheels/c0/1b/ae/c752907c50ad9673ab23730ee731ce853f2cf69b2d98019dcd\n",
      "#17 555.2 Successfully built lit\n",
      "#17 559.8 Installing collected packages: tokenizers, mpmath, lit, cmake, wheel, urllib3, typing-extensions, tqdm, sympy, safetensors, regex, pyyaml, packaging, nvidia-nccl-cu11, nvidia-cufft-cu11, nvidia-cuda-nvrtc-cu11, networkx, MarkupSafe, idna, fsspec, filelock, charset-normalizer, certifi, requests, nvidia-nvtx-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, jinja2, nvidia-cusolver-cu11, nvidia-cudnn-cu11, huggingface-hub, transformers, triton, torch, embed-lib\n",
      "#17 671.3 Successfully installed MarkupSafe-2.1.3 certifi-2023.11.17 charset-normalizer-3.3.2 cmake-3.28.1 embed-lib-1.0.0 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.19.4 idna-3.6 jinja2-3.1.2 lit-17.0.6 mpmath-1.3.0 networkx-3.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 packaging-23.2 pyyaml-6.0.1 regex-2023.10.3 requests-2.31.0 safetensors-0.4.1 sympy-1.12 tokenizers-0.13.3 torch-2.0.1 tqdm-4.65.0 transformers-4.30.1 triton-2.0.0 typing-extensions-4.9.0 urllib3-2.1.0 wheel-0.42.0\n",
      "#17 671.3 \n",
      "#17 671.3 [notice] A new release of pip is available: 23.0.1 -> 23.3.2\n",
      "#17 671.3 [notice] To update, run: /root/venv_embed_loop/bin/python -m pip install --upgrade pip\n",
      "#17 DONE 673.0s\n",
      "\n",
      "#18 [14/14] COPY ./build/embed.py ./service_embed_loop/embed.py\n",
      "#18 DONE 0.0s\n",
      "\n",
      "#19 exporting to image\n",
      "#19 exporting layers\n",
      "#19 exporting layers 10.6s done\n",
      "#19 writing image sha256:bf19f3b2b9ddb50ca4a29c56dc9bafd63e7c3b3ee30a369b5e3f1062365ee753 done\n",
      "#19 naming to docker.io/library/embed_text_service:latest done\n",
      "#19 DONE 10.6s\n"
     ]
    }
   ],
   "source": [
    "# If you are building on a Mac with an ARM CPU, building and running for AMD64 may\n",
    "# be quite slow due to CPU emulation (e.g. perf tests will look really slow).\n",
    "# To get around this, you can start by building asnd testing locally for ARM CPU\n",
    "# (However, since Snowpark container services uses AMD64 CPUs, you still need to do the AMD64 build before deploying!)\n",
    "# buildlib.build(build_dir=BUILD_DIR, platform=\"linux/arm64\", tag=\"arm_for_local_testing\")\n",
    "buildlib.build(build_dir=BUILD_DIR, platform=\"linux/amd64\", tag=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test locally\n",
    "\n",
    "You can use `pytest` on the tests in `testing/tests` to get a quick check on whether the service is not working as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m============================= test session starts ==============================\u001b[0m\n",
      "platform darwin -- Python 3.8.18, pytest-7.4.3, pluggy-1.3.0\n",
      "rootdir: /Users/lmerrick/Code/sfguide-text-embedding-snowpark-container-service\n",
      "collected 1 item\n",
      "\n",
      "../../testing/tests/test_end_to_end.py \u001b[32m.\u001b[0m\u001b[32m                                 [100%]\u001b[0m\n",
      "\n",
      "\u001b[32m============================== \u001b[32m\u001b[1m1 passed\u001b[0m\u001b[32m in 26.55s\u001b[0m\u001b[32m ==============================\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "test_path = BUILD_DIR.parent / \"testing\" / \"tests\" / \"test_end_to_end.py\"\n",
    "# with buildlib.run_container_context(tag=\"arm_for_local_testing\"):\n",
    "with buildlib.run_container_context():\n",
    "    pytest.main([str(test_path)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance testing\n",
    "\n",
    "You can use the performance testing scripts to see how your configuration works. Keep in mind that [Snowflake has a 30 second timeout](https://docs.snowflake.com/en/sql-reference/external-functions-implementation) that can be triggered if too many big simultaneous requests bog down the service. Setting small batch sizes and a small internal queue size will help mitigate timeout issues. The default values are conservative (good for running medium-sized models on CPU), but you may want to try different parameters (by supplying more keyword arguments in the `config.py` file above), especially if you will be using a large CPU instance type or a GPU instance type in the compute pool that runs your service. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buildlib.start_locally(tag=\"arm_for_local_testing\")\n",
    "buildlib.start_locally()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If `last_retry_time` exceeds 30 seconds for any query, that is equivalent to the\n",
    "# conditions in which you can expect a timeout error when serving in Snowflake.\n",
    "!python ../../testing/perf_test_scripts/checking_for_timeouts.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildlib.stop_locally()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy\n",
    "\n",
    "Now that we have build our image and made sure it passes local tests, we can deploy our service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from textwrap import dedent\n",
    "import snowflake.connector\n",
    "\n",
    "\n",
    "# Edit these parameters.\n",
    "connection_params = {\n",
    "    \"account\"   : input(\"Account: \"),\n",
    "    \"user\"      : input(\"Username: \"),\n",
    "}\n",
    "\n",
    "# Establish and configure connection.\n",
    "connection_params[\"password\"] = getpass(f\"Password:\")\n",
    "connection = snowflake.connector.connect(**connection_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup prerequisites\n",
    "\n",
    "To deploy a service, you need to have a compute pool, a database and schema, and an image repository already set up. You also need a role that you can assume which has the permissions necessary to set up the service. Below is an example setup script.\n",
    "\n",
    "**NOTE:** If you write your embedding code to exploit GPU acceleration (as we do in this walkthrough), choosing a GPU instance type (like GPU_3, which we use in the walkthrough) for your compute pool will unlock strong text embedding throughput. However, for lighweight models and low throughput use-cases (e.g. less than 10 short single-row embeddings per second), you may be able to get by on a modest CPU instance type like STANDARD_1 or STANDARD_3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role accountadmin;\n",
      "-- create a compute pool\n",
      "create compute pool if not exists text_embed_gpu\n",
      "min_nodes = 1\n",
      "max_nodes = 1\n",
      "instance_family = gpu_3;\n",
      "-- create a new database and schema\n",
      "create or replace database custom_ml;\n",
      "create or replace schema ml;\n",
      "-- give yourself a new role to manage text embedding\n",
      "create or replace role embed_text_manager;\n",
      "grant all on database custom_ml to role embed_text_manager;\n",
      "grant all on schema custom_ml.ml to role embed_text_manager;\n",
      "grant usage on compute pool text_embed_gpu to role embed_text_manager;\n",
      "grant monitor on compute pool text_embed_gpu to role embed_text_manager;\n",
      "grant role embed_text_manager to user admin;\n",
      "-- use the new role to set up the image repo and service spec stage\n",
      "use role embed_text_manager;\n",
      "use database custom_ml;\n",
      "use schema ml;\n",
      "create or replace image repository image_repo;\n",
      "create or replace stage service_specs;\n"
     ]
    }
   ],
   "source": [
    "compute_pool = \"text_embed_gpu\"\n",
    "database = \"custom_ml\"\n",
    "schema = \"ml\"\n",
    "role = \"embed_text_manager\"\n",
    "image_repository = \"image_repo\"\n",
    "spec_stage = \"service_specs\"\n",
    "setup_sql_commands = dedent(\n",
    "    f\"\"\"\n",
    "    use role accountadmin;\n",
    "\n",
    "    -- create a compute pool\n",
    "    create compute pool if not exists {compute_pool}\n",
    "    min_nodes = 1\n",
    "    max_nodes = 1\n",
    "    instance_family = gpu_3;\n",
    "\n",
    "    -- create a new database and schema\n",
    "    create or replace database {database};\n",
    "    create or replace schema {schema};\n",
    "\n",
    "    -- give yourself a new role to manage text embedding\n",
    "    create or replace role {role};\n",
    "    grant all on database {database} to role {role};\n",
    "    grant all on schema {database}.{schema} to role {role};\n",
    "    grant usage on compute pool {compute_pool} to role {role};\n",
    "    grant monitor on compute pool {compute_pool} to role {role};\n",
    "    grant role embed_text_manager to user {connection_params[\"user\"]};\n",
    "\n",
    "    -- use the new role to set up the image repo and service spec stage\n",
    "    use role {role};\n",
    "    use database {database};\n",
    "    use schema {schema};\n",
    "    create or replace image repository {image_repository};\n",
    "    create or replace stage {spec_stage};\n",
    "    \"\"\"\n",
    ")\n",
    "buildlib._run_sql(connection, setup_sql_commands)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Push the image\n",
    "\n",
    "You can use the `buildlib.push` convenience function to push your image. If you're already logged into the image repository in Docker, you can omit the `username` and `password` arguments and pass `skip_login` instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Login Succeeded\n",
      "Pushing <accountname>.registry.snowflakecomputing.com/custom_ml/ml/image_repo/embed_text_service:latest\n",
      "The push refers to repository [<accountname>.registry.snowflakecomputing.com/custom_ml/ml/image_repo/embed_text_service]\n",
      "20d0cc1c6a81: Preparing\n",
      "af514d472114: Preparing\n",
      "7591540d1176: Preparing\n",
      "518c15b0779f: Preparing\n",
      "f4724c52227c: Preparing\n",
      "6e716c10ddae: Preparing\n",
      "51084bf0cad3: Preparing\n",
      "7d123e6b7f6d: Preparing\n",
      "bc51bc5bba77: Preparing\n",
      "07d57957db0f: Preparing\n",
      "7cb7ebd732dc: Preparing\n",
      "fc4161923a73: Preparing\n",
      "5f70bf18a086: Preparing\n",
      "30cb8a64ad61: Preparing\n",
      "600c676771a0: Preparing\n",
      "6ac15100dff6: Preparing\n",
      "40f0eb1871b9: Preparing\n",
      "8d113b7b997c: Preparing\n",
      "cd77f58b80cd: Preparing\n",
      "e4b1bddcbe63: Preparing\n",
      "765423415d69: Preparing\n",
      "7b9433fba79b: Preparing\n",
      "256d88da4185: Preparing\n",
      "6e716c10ddae: Waiting\n",
      "51084bf0cad3: Waiting\n",
      "7d123e6b7f6d: Waiting\n",
      "bc51bc5bba77: Waiting\n",
      "07d57957db0f: Waiting\n",
      "7cb7ebd732dc: Waiting\n",
      "fc4161923a73: Waiting\n",
      "5f70bf18a086: Waiting\n",
      "30cb8a64ad61: Waiting\n",
      "600c676771a0: Waiting\n",
      "6ac15100dff6: Waiting\n",
      "40f0eb1871b9: Waiting\n",
      "8d113b7b997c: Waiting\n",
      "cd77f58b80cd: Waiting\n",
      "e4b1bddcbe63: Waiting\n",
      "765423415d69: Waiting\n",
      "7b9433fba79b: Waiting\n",
      "256d88da4185: Waiting\n",
      "20d0cc1c6a81: Pushed\n",
      "6e716c10ddae: Pushed\n",
      "51084bf0cad3: Pushed\n",
      "7d123e6b7f6d: Pushed\n",
      "bc51bc5bba77: Pushed\n",
      "07d57957db0f: Pushed\n",
      "518c15b0779f: Pushed\n",
      "fc4161923a73: Pushed\n",
      "7591540d1176: Pushed\n",
      "5f70bf18a086: Pushed\n",
      "f4724c52227c: Pushed\n",
      "600c676771a0: Pushed\n",
      "6ac15100dff6: Pushed\n",
      "40f0eb1871b9: Pushed\n",
      "7cb7ebd732dc: Pushed\n",
      "cd77f58b80cd: Pushed\n",
      "e4b1bddcbe63: Pushed\n",
      "7b9433fba79b: Pushed\n",
      "765423415d69: Pushed\n",
      "256d88da4185: Pushed\n",
      "30cb8a64ad61: Pushed\n",
      "8d113b7b997c: Pushed\n",
      "af514d472114: Pushed\n",
      "latest: digest: sha256:4252d88c8f07a8cf9d4b546ffdb32c6397fba4c7b80b4a4b8e182d59c3fc6688 size: 5155\n"
     ]
    }
   ],
   "source": [
    "image_repository_url = (\n",
    "    f\"{connection_params['account']}.registry.snowflakecomputing.com/\"\n",
    "    f\"{database}/{schema}/{image_repository}\"\n",
    ")\n",
    "buildlib.push(\n",
    "    repo_url=image_repository_url,\n",
    "    username=connection_params[\"user\"],\n",
    "    password=connection_params[\"password\"],\n",
    "    tag=\"latest\",\n",
    "    skip_login=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the service\n",
    "\n",
    "We're almost there! We've built our image and pushed it, now we just need to put together a service spec and run a `create service ...;` statement. Luckily, `buildlib.deploy_service` makes this quite straightforward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role embed_text_manager;\n",
      "use database custom_ml;\n",
      "use schema ml;\n",
      "drop service if exists embed_text_service;\n",
      "create service embed_text_service\n",
      "    in compute pool text_embed_gpu\n",
      "    from specification $$\n",
      "        spec:\n",
      "          containers:\n",
      "          - image: /custom_ml/ml/image_repo/embed_text_service:latest\n",
      "            name: embed-text-service\n",
      "            readinessProbe:\n",
      "              path: /healthcheck\n",
      "              port: 8000\n",
      "            resources:\n",
      "              limits:\n",
      "                nvidia.com/gpu: 1\n",
      "              requests:\n",
      "                nvidia.com/gpu: 1\n",
      "          endpoint:\n",
      "          - name: endpoint\n",
      "            port: 8000\n",
      "\n",
      "    $$\n",
      "    min_instances = 1\n",
      "    max_instances = 1;\n",
      "create or replace function _embed_to_base64(input string)\n",
      "    returns string\n",
      "    service=embed_text_service!endpoint\n",
      "    max_batch_rows=4\n",
      "    as '/embed';\n",
      "create or replace function _unpack_binary_array(B binary)\n",
      "    returns array\n",
      "    language javascript\n",
      "    immutable\n",
      "    as\n",
      "    $$\n",
      "        return Array.from(new Float32Array(B.buffer));\n",
      "    $$;\n",
      "create or replace function embed_text(input string)\n",
      "    returns vector(float,768)\n",
      "    language SQL\n",
      "    as\n",
      "    $$_unpack_binary_array(to_binary(_embed_to_base64(input), 'BASE64'))::vector(float,768)$$;\n"
     ]
    }
   ],
   "source": [
    "buildlib.deploy_service(\n",
    "    connection,\n",
    "    embedding_dim=MODEL_EMBEDDING_DIM,\n",
    "    # If you use a CPU-instance-type pool, set `num_gpus=0`.\n",
    "    num_gpus=1,\n",
    "    role=role,\n",
    "    database=database,\n",
    "    schema=schema,\n",
    "    spec_stage=spec_stage,\n",
    "    compute_pool=compute_pool,\n",
    "    image_repository=image_repository,\n",
    "    # If for some reason your image repository is in a different database/schema\n",
    "    # you can specify a separate database/schema, too. Buildlib expects the spec\n",
    "    # stage to be in the same database/schema as the service, though.\n",
    "    image_database=database,\n",
    "    image_schema=schema,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watch it come up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'status': 'READY', 'message': 'Running', 'containerName': 'embed-text-service', 'instanceId': '0', 'serviceName': 'EMBED_TEXT_SERVICE', 'image': '<accountname>.registry.snowflakecomputing.com/custom_ml/ml/image_repo/embed_text_service:latest', 'restartCount': 0, 'startTime': '2023-12-19T01:00:50Z'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.loads(connection.cursor().execute(\"CALL SYSTEM$GET_SERVICE_STATUS('custom_ml.ml.embed_text_service');\").fetchone()[0])[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========\n",
      "== CUDA ==\n",
      "==========\n",
      "\n",
      "CUDA Version 12.1.0\n",
      "\n",
      "Container image Copyright (c) 2016-2023, NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
      "\n",
      "This container image and its contents are governed by the NVIDIA Deep Learning Container License.\n",
      "By pulling and using the container, you accept the terms and conditions of this license:\n",
      "https://developer.nvidia.com/ngc/nvidia-deep-learning-container-license\n",
      "\n",
      "A copy of this license is made available in this container at /NGC-DL-CONTAINER-LICENSE for your convenience.\n",
      "\n",
      "*************************\n",
      "** DEPRECATION NOTICE! **\n",
      "*************************\n",
      "THIS IMAGE IS DEPRECATED and is scheduled for DELETION.\n",
      "    https://gitlab.com/nvidia/container-images/cuda/blob/master/doc/support-policy.md\n",
      "\n",
      "INFO:     Started server process [1]\n",
      "INFO:     Waiting for application startup.\n",
      "2023-12-19 01:00:51,708 __main__ INFO: Beginning application setup\n",
      "2023-12-19 01:00:51,708 __main__ INFO: Allocating shared-memory data structures\n",
      "2023-12-19 01:00:51,714 __main__ INFO: Launching log listener thread\n",
      "2023-12-19 01:00:51,715 __main__ INFO: Spawning the embed loop process\n",
      "2023-12-19 01:00:51,717 __main__ INFO: Preparing API state\n",
      "2023-12-19 01:00:51,717 service_api.api INFO: Initializing job id counter\n",
      "2023-12-19 01:00:51,717 service_api.api INFO: Initializing query id cache\n",
      "2023-12-19 01:00:51,717 service_api.api INFO: Opening embedding input queue and result map\n",
      "2023-12-19 01:00:51,718 __main__ INFO: Application setup complete\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "INFO:     10.16.116.22:46884 - \"GET /healthcheck HTTP/1.1\" 200 OK\n",
      "2023-12-19 01:00:53,847 embedding_loop_subprocess INFO: Embed loop starting\n",
      "2023-12-19 01:00:53,847 embedding_loop_subprocess INFO: Opening input queue and result map\n",
      "2023-12-19 01:00:53,847 embedding_loop_subprocess INFO: Setting up embedding process SIGTERM handling\n",
      "2023-12-19 01:00:53,847 embedding_loop_subprocess INFO: [get_embed_fn]Loading model from disk to memory\n",
      "INFO:     10.16.116.22:46898 - \"GET /healthcheck HTTP/1.1\" 200 OK\n",
      "2023-12-19 01:00:55,411 embedding_loop_subprocess INFO: [get_embed_fn]CUDA available: True\n",
      "2023-12-19 01:00:55,411 embedding_loop_subprocess INFO: Starting embedding loop\n",
      "INFO:     10.16.116.22:46904 - \"GET /healthcheck HTTP/1.1\" 200 OK\n",
      "INFO:     10.16.116.22:46920 - \"GET /healthcheck HTTP/1.1\" 200 OK\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(connection.cursor().execute(\"CALL SYSTEM$GET_SERVICE_LOGS('custom_ml.ml.embed_text_service', '0', 'embed-text-service');\").fetchone()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!\n",
    "\n",
    "Text embedding should now be live! Here's an example of giving all users access to the `embed_text` function and calling this function via a preexisting warehouse called `compute_wh`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use role accountadmin;\n",
      "grant usage on database custom_ml to role public;\n",
      "grant usage on schema custom_ml.ml to role public;\n",
      "use role embed_text_manager;\n",
      "grant usage on function custom_ml.ml.embed_text(text) to role public;\n",
      "use role public;\n",
      "use warehouse compute_wh;\n",
      "[0.0032345708459615707, -0.008582721464335918, -0.037687599658966064, -0.00331854703836143, 0.04481322318315506, -0.03027017042040825, 0.0320584774017334, 0.05281173065304756, -0.0010827032383531332, -0.01863020844757557, -0.02498818002641201, 0.047690510749816895, -0.0871417447924614, 0.01861654967069626, -0.031328581273555756, 0.00654643913730979, 0.02404150180518627, -0.00824214331805706, 0.03759678453207016, -0.020063813775777817, -0.048249438405036926, -0.05238138884305954, 0.04970218241214752, -0.008793247863650322, 0.005695943720638752, 0.0111410366371274, -0.005848483182489872, 0.001621723989956081, -0.0469050332903862, -0.03712565079331398, 0.01579623855650425, 0.03618093207478523, 0.058089494705200195, -0.0515451580286026, -0.07014214992523193, 0.0005390692967921495, -0.04565751180052757, 0.02375316247344017, -0.0619567334651947, -0.02124839462339878, -0.00020677225256804377, -0.002343712607398629, -0.02817695215344429, 0.046608589589595795, -0.04741368442773819, -0.03751217946410179, -0.0541919469833374, 0.08486747741699219, -0.01257611159235239, -0.019455142319202423, -0.038634780794382095, 0.07088784873485565, 0.0471099354326725, -0.03310524299740791, 0.00031787712941877544, 0.023767830803990364, -0.0008515582885593176, -0.019622892141342163, -0.02646762691438198, -0.039613500237464905, 0.045153748244047165, 0.020551931113004684, 0.045033860951662064, -0.005189655814319849, 0.005211557727307081, 0.050336163491010666, 0.012325582094490528, 0.0037238583900034428, -0.023086531087756157, -0.0013540490763261914, -0.0006832206854596734, -0.010280565358698368, -0.06326345354318619, -0.04074583575129509, 0.020554758608341217, -0.05523053929209709, 0.014166624285280704, 0.044573210179805756, 0.01328734215348959, 0.03832100331783295, -0.05085976794362068, -0.0316714271903038, 0.04955759271979332, 0.03958050534129143, 0.028277752920985222, -0.05328747630119324, -0.010429085232317448, 0.018599413335323334, -0.011700219474732876, 0.033235207200050354, -0.04309886321425438, -0.055957552045583725, 0.054796002805233, 0.03549443557858467, 0.08157896995544434, -0.03366965427994728, 0.016625557094812393, -0.03832728788256645, 0.007424104493111372, 0.027792926877737045, -0.04136725142598152, -0.05049920454621315, 0.002269984921440482, 0.0013990910956636071, -0.04372590780258179, -0.0372653603553772, -0.0020469778683036566, -0.009532969444990158, -0.01349059958010912, 0.03848285228013992, -0.058372050523757935, -0.022855620831251144, -0.03691936656832695, -0.023567037656903267, -0.033878080546855927, 0.08061540126800537, 0.06645157933235168, -0.04075070470571518, -0.033410217612981796, -0.033587101846933365, 0.0028557772748172283, 0.06657014787197113, 0.037847358733415604, 0.05786082148551941, 0.015719318762421608, 0.030664067715406418, -0.0005838652141392231, 0.05222489684820175, -0.02927931398153305, -0.03846966475248337, 0.06144009530544281, 0.00556621327996254, 0.06415794789791107, -0.027037255465984344, 0.0188452061265707, -0.022558823227882385, -0.027215223759412766, -0.014767136424779892, 0.026407184079289436, -0.0221724733710289, 0.001524556428194046, 0.04444882646203041, 0.026182517409324646, -0.025864623486995697, 0.03713410720229149, 0.01065980177372694, -0.029987668618559837, -0.02436145208775997, -0.07012073695659637, 0.01075016986578703, 0.01585245691239834, 0.01957133039832115, 0.00269346428103745, -0.057328302413225174, -0.03501565381884575, 0.06276962906122208, 0.012129700742661953, -0.007055062334984541, -0.04212718829512596, 0.04088791087269783, 0.027721118181943893, 0.035093627870082855, 0.023027753457427025, 0.029177391901612282, -0.02817785181105137, -0.0024200836196541786, 0.0507049597799778, -0.026553576812148094, 0.03495816886425018, 0.048241276293992996, -0.011079739779233932, -0.04247092455625534, 0.014334838837385178, -0.029275942593812943, -0.041688211262226105, 0.03430695831775665, 0.03469151258468628, 0.007292519323527813, -0.024719029664993286, 0.00927360262721777, -0.05864473059773445, -0.028387615457177162, 0.037907734513282776, 0.015108034946024418, -0.06821542978286743, -0.030396094545722008, 0.046706605702638626, -0.04225943610072136, 0.01999868080019951, 0.04358057305216789, -0.05890105292201042, -0.049275148659944534, 0.035908833146095276, -0.022131770849227905, 0.050640769302845, -0.01663658209145069, 0.002476711291819811, 0.015218467451632023, 0.034517280757427216, 0.036928508430719376, 0.012820297852158546, 0.030766736716032028, -0.0038561804685741663, -0.04964346066117287, -0.05686970800161362, 0.00046988154645077884, 0.052455347031354904, -0.039194341748952866, 0.004436517134308815, 0.021863043308258057, -0.054559335112571716, -0.017457470297813416, 0.03566368669271469, -0.03320388123393059, 0.019615042954683304, 0.0014804889215156436, 0.018833331763744354, -0.04133189842104912, -0.011444257572293282, 0.012654883787035942, 0.07148274779319763, -0.056830063462257385, -0.017140619456768036, 0.01986326090991497, 0.011109425686299801, 0.039698276668787, 0.05614897236227989, -0.010002771392464638, 0.015647364780306816, -0.014174719341099262, -0.028145305812358856, -0.00734255975112319, 0.024026477709412575, -0.014593133702874184, -0.06728219985961914, 0.021900299936532974, 0.00292750122025609, -0.009278647601604462, 0.01619807817041874, -0.009345770813524723, -0.0101593853905797, 0.05633915588259697, -0.03567801043391228, 0.07187274098396301, -0.031198037788271904, -0.04729608818888664, 0.06951569765806198, -0.020339123904705048, -0.006627742201089859, -0.03934551402926445, -0.031118419021368027, -0.021761257201433182, 0.05696069449186325, -0.02510385401546955, 0.03722745180130005, -0.04557522386312485, 0.0054975952953100204, 0.03801807761192322, 0.04856795072555542, 0.021411143243312836, 0.008882429450750351, 0.018622200936079025, 0.018814045935869217, -0.05838035047054291, -0.03869795426726341, -0.03269834816455841, -0.03811541199684143, -0.027758972719311714, 0.056195445358753204, 0.02440166287124157, 0.0291306059807539, -0.0027934571262449026, 0.016204841434955597, -0.0010418068850412965, 0.026160212233662605, -0.053745996206998825, 0.040649063885211945, -0.008270514197647572, -0.013641574420034885, -0.024370042607188225, -0.04870699346065521, 0.07428896427154541, -0.04624105989933014, -0.056875329464673996, 0.022365931421518326, -0.06639110296964645, 0.046029381453990936, -0.038169629871845245, -0.048352960497140884, -0.04349196329712868, 0.025467602536082268, 0.03359169885516167, -0.051905978471040726, 0.004269450902938843, 0.03086729720234871, -0.03346431255340576, 0.02757921814918518, 0.016461186110973358, -0.016013329848647118, 0.02101263962686062, 0.019153937697410583, 0.04203111678361893, 0.041067883372306824, -0.015171228908002377, 0.021217230707406998, -0.033359088003635406, -0.0013787104981020093, -0.04950772970914841, -0.012635547667741776, 0.019843921065330505, -0.00999090913683176, -0.06825201958417892, 0.03023730404675007, -0.016446635127067566, 0.06724615395069122, 0.004126891028136015, -0.03738773241639137, -0.02060944028198719, -0.04760364443063736, -0.025757668539881706, -0.006284426897764206, 0.025465864688158035, 0.04036813601851463, -0.012777919881045818, 0.015153787098824978, -0.03280819207429886, -0.03410067409276962, 0.04176647961139679, -0.05586257576942444, -0.02232770062983036, -0.030991114675998688, 0.04908883199095726, 0.03430211916565895, 0.04150328412652016, -0.010262398049235344, -0.013379647396504879, -0.044465526938438416, -0.020743323490023613, -0.03933733329176903, -0.04079611971974373, 0.016307774931192398, 0.036048952490091324, 0.01290586031973362, -0.046289049088954926, 0.04423364996910095, -0.04449478164315224, 0.003986311610788107, -0.053083740174770355, -0.042611703276634216, -0.00817694142460823, 0.015745045617222786, 0.022189123556017876, -0.004465147387236357, -0.016251280903816223, -0.004776121117174625, -0.03663868457078934, 0.0064454213716089725, 0.027170700952410698, 0.01241648942232132, 0.0014083799906075, 0.02918311208486557, -0.020279012620449066, -0.019821442663669586, -0.02714374102652073, 0.034623172134160995, 0.03046129085123539, -0.0542348176240921, -0.03113633207976818, 0.013402453623712063, -0.027557941153645515, -0.04253640025854111, -0.06097201630473137, -0.009705726057291031, -0.06693261116743088, -0.05723831057548523, -0.029008755460381508, 0.050435613840818405, 0.029205000028014183, -0.03879383206367493, -0.007289587054401636, -0.035765428096055984, -0.13089898228645325, -0.039330631494522095, 0.006843124516308308, -0.04487625136971474, -0.024774376302957535, 0.006893835496157408, 9.681363007985055e-05, -0.008358355611562729, -0.01785847917199135, 0.02025976963341236, 0.05573533847928047, -0.017030691727995872, -0.05071258172392845, -0.022775227203965187, 0.00977132748812437, 0.0014701997861266136, -0.007435152307152748, 0.01718389056622982, -0.038903363049030304, -0.049695175141096115, 0.058286845684051514, 0.0636090487241745, 0.04459450766444206, 0.015729766339063644, -0.005943004507571459, 0.06648281961679459, -0.012513614259660244, 0.04005102813243866, -0.03498639538884163, -0.03130021691322327, -0.014909337274730206, 0.08036654442548752, 0.015209797769784927, -0.04104455187916756, 0.01971444860100746, 0.09719101339578629, 0.029560890048742294, 0.03636510297656059, -0.017695898190140724, 0.010966724716126919, -0.02333449199795723, -0.012461699545383453, 0.005175782833248377, 0.015801601111888885, 0.019514737650752068, 0.001339348847977817, 0.04690204933285713, -0.010049110278487206, 0.04474004730582237, -0.012857832945883274, -0.04734359681606293, -0.01747756265103817, 0.018817346543073654, -0.0055131432600319386, -0.03673423081636429, 0.015562981367111206, -0.05654042586684227, -0.05023549869656563, -0.023327844217419624, 0.05825769901275635, 0.0037205286789685488, 0.04322058707475662, 0.026068013161420822, -0.004698355682194233, -0.032880622893571854, -0.0006140777259133756, -0.004066833760589361, 0.01582840271294117, 0.02492549642920494, 0.0031557241454720497, 0.02632894553244114, 0.011045757681131363, 0.04370410367846489, -0.0005695077707059681, 0.023053152486681938, -0.043534934520721436, 0.01226883102208376, 0.025112716481089592, -0.02146550454199314, 0.0347101166844368, 0.008180944249033928, -0.059947751462459564, -0.04120703041553497, 0.0706120952963829, -0.0006185653037391603, -0.01803574711084366, -0.019309502094984055, 0.025842277333140373, -0.050274964421987534, -0.029379893094301224, -0.003283219877630472, 0.041233621537685394, 0.04234173148870468, -0.0021947657223790884, -0.0003290993336122483, -0.025171861052513123, -0.011338731274008751, 0.05390887334942818, -0.01047383900731802, -0.03352584317326546, 0.012718193233013153, -0.042180974036455154, 0.018633820116519928, -0.01917623169720173, -0.0480748750269413, 0.04582732915878296, 0.051998089998960495, 0.024771863594651222, -0.0468427948653698, -0.03452788665890694, 0.035829707980155945, 0.06229332834482193, -0.031203746795654297, -0.031370073556900024, 0.0015261685475707054, -0.031119972467422485, 0.03141585364937782, 0.002530352445319295, 0.058789629489183426, 0.011459068395197392, 0.019526829943060875, -0.052162546664476395, -0.09366931021213531, 0.013486901298165321, 0.04046133533120155, -0.033724475651979446, 0.024362970143556595, -0.056911926716566086, -0.017129788175225258, -0.057193197309970856, 0.014819837175309658, 0.012524675577878952, -0.041704703122377396, 0.029214896261692047, -0.0379638634622097, -0.024936970323324203, 0.04219368100166321, -0.005726249888539314, -0.03718116134405136, -0.009065484628081322, 0.03356718644499779, -0.029287729412317276, -0.02860548347234726, 0.025082195177674294, 0.007790206931531429, 0.025682000443339348, -0.04405808448791504, -0.005773336160928011, -0.020133718848228455, -0.031618889421224594, -0.04334604740142822, -0.019111711531877518, 0.04437645152211189, -0.004489459563046694, -0.027953505516052246, 0.015378766693174839, -0.05705691874027252, 0.026732955127954483, -0.00636470690369606, 0.011107287369668484, 0.036532603204250336, 0.0032774759456515312, 0.006533581297844648, -0.024306001141667366, 0.013155910186469555, 0.0025239349342882633, 0.05970429629087448, 0.06864218413829803, 0.021352067589759827, -0.04132133349776268, -0.03078116476535797, -0.03133571520447731, 0.0565585158765316, -0.017797833308577538, 0.0024879854172468185, -0.018485790118575096, 0.030314596369862556, -0.05388797074556351, -0.016392886638641357, -0.023004747927188873, -0.03393729403614998, -0.005512085743248463, -0.05620360001921654, -0.04788143187761307, 0.00928556639701128, -0.05088304728269577, -0.013384919613599777, -0.0024260960053652525, -0.0042208461090922356, -0.04695739224553108, 0.0431254580616951, 0.0628177598118782, 0.06171068176627159, -0.05287989601492882, -0.06077686697244644, 0.0327647402882576, 0.05984969809651375, 0.03164208307862282, -0.048411816358566284, 0.02925749495625496, 0.041846808046102524, 0.06389134377241135, 0.020849917083978653, -0.02550962008535862, -0.015177368186414242, 0.02919299341738224, -0.053991857916116714, -0.017363576218485832, 0.05923077091574669, -0.027101127430796623, 0.01729816570878029, 0.001092260703444481, -0.03623432666063309, 0.020924778655171394, 0.0031498291064053774, -0.036068934947252274, 0.03118402697145939, -0.015126746147871017, 0.05981265753507614, 0.022671189159154892, 0.047575708478689194, 0.025634320452809334, 0.02825053408741951, 0.013951266184449196, 0.05345401540398598, -0.07497474551200867, 0.017616715282201767, -0.04146153852343559, 0.05247743800282478, 0.04288845509290695, -0.025855982676148415, -0.02262900583446026, 0.033759552985429764, 0.00761538278311491, -0.031995225697755814, 0.016573689877986908, 0.0087564866989851, -0.018932292237877846, -0.011382781900465488, 0.028675168752670288, 0.015836328268051147, -0.02806169167160988, 0.0012489757500588894, 0.04931534454226494, -0.08422556519508362, 0.005384707823395729, 0.04393501952290535, 0.029645802453160286, -0.02946753427386284, 0.030139893293380737, 0.058141279965639114, 0.006047970615327358, 0.0029457597993314266, -0.06205751746892929, 0.01821347512304783, -0.02476508356630802, 0.045028772205114365, 0.05940727889537811, 0.034301020205020905, 0.02212672121822834, 0.02590090036392212, -0.04829997569322586, -0.01125334482640028, 0.027486629784107208, -0.03944988548755646, 0.023094894364476204, 0.049828607589006424, 0.0009145215735770762, 0.051797326654195786, -0.01068074256181717, 0.03720038756728172, 0.0065806107595562935, 0.021777980029582977, 0.037561241537332535, -0.014196679927408695, 0.03795485198497772, 0.03396862745285034, 0.07082850486040115, -0.009579764679074287, -0.023607712239027023, -0.02712167426943779, 0.017317073419690132, 0.008034477941691875, 0.015288134105503559, 0.05484815314412117, -0.006130485329777002, 0.008768072351813316, -0.041861940175294876, 0.0034304598812013865, 0.055139072239398956, 0.07759568840265274, 0.00026353177963756025, -0.012449652887880802, 0.04496564716100693, -0.016897208988666534, 0.019755957648158073, -0.018193291500210762, 0.004042868502438068, 0.036173317581415176, -0.014262602664530277, 0.061108916997909546, -0.008766591548919678, 0.012230983935296535, 0.06612981855869293, 0.0010183387203142047, -0.017167339101433754, 0.018279261887073517, 0.02291157841682434, -0.061329588294029236, -0.043122366070747375, -0.04395230486989021, 0.00595659576356411, -0.00918183010071516, 0.026293689385056496, -0.010127068497240543, -0.05528244748711586, -0.013871715404093266, -0.048463523387908936, -0.012579579837620258, 0.010278123430907726, -0.013752308674156666, -0.026071468368172646, -0.05300530418753624, 0.045372504740953445, 0.02409517951309681, 0.005562145262956619, 0.048832718282938004, 0.03244475647807121, 0.017139427363872528, -0.002919759601354599, -0.022694362327456474, -0.025622785091400146, 0.0676800087094307, -0.077403225004673, 0.03403902426362038, -0.05236018821597099, 0.07928456366062164, 0.03943270444869995, -0.03734733909368515, -0.0556814931333065, 0.023260971531271935, -0.035514913499355316, -0.002139979973435402, 0.041215527802705765, 0.0348442867398262, 0.05422481521964073, -0.02700253576040268, -0.030971309170126915, -0.032199062407016754, -0.025969577953219414, 0.030777066946029663, -0.012837949208915234, 0.06525110453367233, 0.016723617911338806, 0.0265816580504179, -0.07447011023759842, 0.04154309630393982, -0.008134497329592705, 0.033832527697086334, -0.060398124158382416, 0.028016963973641396, 0.039296481758356094, -0.018497828394174576, -0.02280028723180294, 0.018827715888619423, 0.011827821843326092, -0.05652578920125961, 0.047819215804338455, 0.0462932251393795, 0.03512610122561455, 0.03758910670876503, -0.038431379944086075, -0.0039399792440235615, -0.03729979321360588, -0.06414683908224106, -0.0321008563041687, 0.02482030913233757, 0.04381037876009941, -0.039291221648454666, 0.023994402959942818, -0.037749938666820526, 0.049016036093235016, 0.029084062203764915, -0.016428040340542793, -0.017010321840643883, 0.04046604037284851, 0.03543247655034065]\n"
     ]
    }
   ],
   "source": [
    "buildlib._run_sql(\n",
    "    connection,\n",
    "    \"use role accountadmin; \"\n",
    "    \"grant usage on database custom_ml to role public; \"\n",
    "    \"grant usage on schema custom_ml.ml to role public; \"\n",
    "    \"use role embed_text_manager; \"\n",
    "    \"grant usage on function custom_ml.ml.embed_text(text) to role public; \"\n",
    "    \"use role public; \"\n",
    "    \"use warehouse compute_wh;\"\n",
    ")\n",
    "print(connection.cursor().execute(\"select embed_text('hello world!');\").fetchone()[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "embed-standalone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
